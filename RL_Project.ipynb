{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahdtamerr21/RL-Project/blob/main/RL_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMnRpMO2Go7-",
        "outputId": "52d5d14c-c68f-4edd-cba8-31a4deabfaa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.4.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3[extra])\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.17.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Collecting ale-py>=0.9.0 (from stable-baselines3[extra])\n",
            "  Downloading ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (11.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py>=0.9.0->stable-baselines3[extra]) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra])\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Downloading ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.4.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium, ale-py, stable-baselines3\n",
            "Successfully installed ale-py-0.10.1 farama-notifications-0.0.4 gymnasium-1.0.0 stable-baselines3-2.4.0\n",
            "Requirement already satisfied: gymnasium[all] in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (0.0.4)\n",
            "Requirement already satisfied: ale-py>=0.9 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (0.10.1)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[all])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (2.6.1)\n",
            "Collecting swig==4.* (from gymnasium[all])\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting mujoco-py<2.2,>=2.1 (from gymnasium[all])\n",
            "  Downloading mujoco_py-2.1.2.14-py3-none-any.whl.metadata (669 bytes)\n",
            "Collecting cython<3 (from gymnasium[all])\n",
            "  Downloading Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.1 kB)\n",
            "Collecting mujoco>=2.1.5 (from gymnasium[all])\n",
            "  Downloading mujoco-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (2.36.1)\n",
            "Requirement already satisfied: jax>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (0.4.33)\n",
            "Requirement already satisfied: jaxlib>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (0.4.33)\n",
            "Requirement already satisfied: flax>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (0.8.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (2.5.1+cu121)\n",
            "Requirement already satisfied: opencv-python>=3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (3.8.0)\n",
            "Requirement already satisfied: moviepy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[all]) (1.0.3)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.5.0->gymnasium[all]) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax>=0.5.0->gymnasium[all]) (0.2.4)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.5.0->gymnasium[all]) (0.6.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.5.0->gymnasium[all]) (0.1.71)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.5.0->gymnasium[all]) (13.9.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.5.0->gymnasium[all]) (6.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.14.1->gymnasium[all]) (11.0.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.0->gymnasium[all]) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.0->gymnasium[all]) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.0->gymnasium[all]) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gymnasium[all]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gymnasium[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gymnasium[all]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gymnasium[all]) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gymnasium[all]) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gymnasium[all]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->gymnasium[all]) (2.8.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.0->gymnasium[all]) (4.4.2)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.0->gymnasium[all]) (0.5.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.0->gymnasium[all]) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.0->gymnasium[all]) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.0->gymnasium[all]) (0.1.10)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.1.5->gymnasium[all]) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.1.5->gymnasium[all]) (1.11.0)\n",
            "Collecting glfw (from mujoco>=2.1.5->gymnasium[all])\n",
            "  Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.1.5->gymnasium[all]) (3.1.7)\n",
            "Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.10/dist-packages (from mujoco-py<2.2,>=2.1->gymnasium[all]) (1.17.1)\n",
            "Collecting fasteners~=0.15 (from mujoco-py<2.2,>=2.1->gymnasium[all])\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->gymnasium[all]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->gymnasium[all]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->gymnasium[all]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->gymnasium[all]) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->gymnasium[all]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->gymnasium[all]) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.10->mujoco-py<2.2,>=2.1->gymnasium[all]) (2.22)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy>=1.0.0->gymnasium[all]) (75.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->gymnasium[all]) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->gymnasium[all]) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.5.0->gymnasium[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.5.0->gymnasium[all]) (2.18.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[all]) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[all]) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->gymnasium[all]) (3.0.2)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.5.0->gymnasium[all]) (0.1.88)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.5.0->gymnasium[all]) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.5.0->gymnasium[all]) (4.25.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.5.0->gymnasium[all]) (4.11.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.87->optax->flax>=0.5.0->gymnasium[all]) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.5.0->gymnasium[all]) (0.1.2)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mujoco-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mujoco_py-2.1.2.14-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (box2d-py)\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting snake-gym\n",
            "  Downloading snake_gym-1.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading snake_gym-1.8-py3-none-any.whl (2.8 kB)\n",
            "Installing collected packages: snake-gym\n",
            "Successfully installed snake-gym-1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3[extra]  # Install SB3 with additional dependencies\n",
        "!pip install gymnasium[all]            # Install Gymnasium\n",
        "!pip install snake-gym                 # Install the Snake environment\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import snake_gym  # Environment for Snake\n",
        "from stable_baselines3 import DQN, PPO\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKAyNqwIHBcg",
        "outputId": "9669365d-844a-4b1f-bcf3-f9dee96af9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
            "  from jax import xla_computation as _xla_computation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the environment\n",
        "env = gym.make('snake-v0')\n",
        "\n",
        "# Initialize the DQN model\n",
        "dqn_model = DQN('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "dqn_model.learn(total_timesteps=100000)\n",
        "\n",
        "# Save the trained model\n",
        "dqn_model.save(\"dqn_snake\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "IpwpgpoMHBvB",
        "outputId": "93ba5012-835e-47bb-aced-a42a13f34de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'snake_gym.envs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c5e2c081fb39>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'snake-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initialize the DQN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdqn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MlpPolicy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# Assume it's a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0menv_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"render_mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'snake_gym.envs'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snake-gym --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKL3Rd2OHCLV",
        "outputId": "403d712e-d620-483d-edb2-76607137c43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: snake-gym in /usr/local/lib/python3.10/dist-packages (1.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import snake_gym  # Try importing the Snake environment again\n"
      ],
      "metadata": {
        "id": "0n8swmXAHCp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "print(gym.envs.registry.all())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIF6FQKuHC6z",
        "outputId": "bc6e0994-385f-4a47-e629-0e6d18a84dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values([EnvSpec(id='CartPole-v0', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=195.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CartPole', version=0), EnvSpec(id='CartPole-v1', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CartPole', version=1), EnvSpec(id='MountainCar-v0', entry_point='gym.envs.classic_control.mountain_car:MountainCarEnv', reward_threshold=-110.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='MountainCar', version=0), EnvSpec(id='MountainCarContinuous-v0', entry_point='gym.envs.classic_control.continuous_mountain_car:Continuous_MountainCarEnv', reward_threshold=90.0, nondeterministic=False, max_episode_steps=999, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='MountainCarContinuous', version=0), EnvSpec(id='Pendulum-v1', entry_point='gym.envs.classic_control.pendulum:PendulumEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Pendulum', version=1), EnvSpec(id='Acrobot-v1', entry_point='gym.envs.classic_control.acrobot:AcrobotEnv', reward_threshold=-100.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Acrobot', version=1), EnvSpec(id='LunarLander-v2', entry_point='gym.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='LunarLander', version=2), EnvSpec(id='LunarLanderContinuous-v2', entry_point='gym.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'continuous': True}, namespace=None, name='LunarLanderContinuous', version=2), EnvSpec(id='BipedalWalker-v3', entry_point='gym.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=1600, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='BipedalWalker', version=3), EnvSpec(id='BipedalWalkerHardcore-v3', entry_point='gym.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=2000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'hardcore': True}, namespace=None, name='BipedalWalkerHardcore', version=3), EnvSpec(id='CarRacing-v2', entry_point='gym.envs.box2d.car_racing:CarRacing', reward_threshold=900, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CarRacing', version=2), EnvSpec(id='Blackjack-v1', entry_point='gym.envs.toy_text.blackjack:BlackjackEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'sab': True, 'natural': False}, namespace=None, name='Blackjack', version=1), EnvSpec(id='FrozenLake-v1', entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.7, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'map_name': '4x4'}, namespace=None, name='FrozenLake', version=1), EnvSpec(id='FrozenLake8x8-v1', entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.85, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'map_name': '8x8'}, namespace=None, name='FrozenLake8x8', version=1), EnvSpec(id='CliffWalking-v0', entry_point='gym.envs.toy_text.cliffwalking:CliffWalkingEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CliffWalking', version=0), EnvSpec(id='Taxi-v3', entry_point='gym.envs.toy_text.taxi:TaxiEnv', reward_threshold=8, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Taxi', version=3), EnvSpec(id='Reacher-v2', entry_point='gym.envs.mujoco:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Reacher', version=2), EnvSpec(id='Reacher-v4', entry_point='gym.envs.mujoco.reacher_v4:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Reacher', version=4), EnvSpec(id='Pusher-v2', entry_point='gym.envs.mujoco:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Pusher', version=2), EnvSpec(id='Pusher-v4', entry_point='gym.envs.mujoco.pusher_v4:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Pusher', version=4), EnvSpec(id='InvertedPendulum-v2', entry_point='gym.envs.mujoco:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedPendulum', version=2), EnvSpec(id='InvertedPendulum-v4', entry_point='gym.envs.mujoco.inverted_pendulum_v4:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedPendulum', version=4), EnvSpec(id='InvertedDoublePendulum-v2', entry_point='gym.envs.mujoco:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=2), EnvSpec(id='InvertedDoublePendulum-v4', entry_point='gym.envs.mujoco.inverted_double_pendulum_v4:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=4), EnvSpec(id='HalfCheetah-v2', entry_point='gym.envs.mujoco:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HalfCheetah', version=2), EnvSpec(id='HalfCheetah-v3', entry_point='gym.envs.mujoco.half_cheetah_v3:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HalfCheetah', version=3), EnvSpec(id='HalfCheetah-v4', entry_point='gym.envs.mujoco.half_cheetah_v4:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HalfCheetah', version=4), EnvSpec(id='Hopper-v2', entry_point='gym.envs.mujoco:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Hopper', version=2), EnvSpec(id='Hopper-v3', entry_point='gym.envs.mujoco.hopper_v3:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Hopper', version=3), EnvSpec(id='Hopper-v4', entry_point='gym.envs.mujoco.hopper_v4:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Hopper', version=4), EnvSpec(id='Swimmer-v2', entry_point='gym.envs.mujoco:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Swimmer', version=2), EnvSpec(id='Swimmer-v3', entry_point='gym.envs.mujoco.swimmer_v3:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Swimmer', version=3), EnvSpec(id='Swimmer-v4', entry_point='gym.envs.mujoco.swimmer_v4:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Swimmer', version=4), EnvSpec(id='Walker2d-v2', entry_point='gym.envs.mujoco:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Walker2d', version=2), EnvSpec(id='Walker2d-v3', entry_point='gym.envs.mujoco.walker2d_v3:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Walker2d', version=3), EnvSpec(id='Walker2d-v4', entry_point='gym.envs.mujoco.walker2d_v4:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Walker2d', version=4), EnvSpec(id='Ant-v2', entry_point='gym.envs.mujoco:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Ant', version=2), EnvSpec(id='Ant-v3', entry_point='gym.envs.mujoco.ant_v3:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Ant', version=3), EnvSpec(id='Ant-v4', entry_point='gym.envs.mujoco.ant_v4:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Ant', version=4), EnvSpec(id='Humanoid-v2', entry_point='gym.envs.mujoco:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Humanoid', version=2), EnvSpec(id='Humanoid-v3', entry_point='gym.envs.mujoco.humanoid_v3:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Humanoid', version=3), EnvSpec(id='Humanoid-v4', entry_point='gym.envs.mujoco.humanoid_v4:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Humanoid', version=4), EnvSpec(id='HumanoidStandup-v2', entry_point='gym.envs.mujoco:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HumanoidStandup', version=2), EnvSpec(id='HumanoidStandup-v4', entry_point='gym.envs.mujoco.humanoidstandup_v4:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HumanoidStandup', version=4), EnvSpec(id='snake-v0', entry_point='snake_gym.envs:SnakeEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='snake', version=0), EnvSpec(id='snake-tiled-v0', entry_point='snake_gym.envs:SnakeEnvTiled', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='snake-tiled', version=0)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:421: UserWarning: \u001b[33mWARN: The `registry.all` method is deprecated. Please use `registry.values` instead.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('correct-snake-env-name')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "7ZUCWwqEHfWS",
        "outputId": "4a7a999f-1d7c-4046-d0cf-d32ec09e0f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameNotFound",
          "evalue": "Environment correct-snake-env-name doesn't exist. ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6f80f335fcce>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'correct-snake-env-name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0m_check_version_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No registered env with id: {id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0m_check_name_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0msuggestion_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Did you mean: `{suggestion[0]}`?\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msuggestion\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     raise error.NameNotFound(\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;34mf\"Environment {name} doesn't exist{namespace_msg}. {suggestion_msg}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     )\n",
            "\u001b[0;31mNameNotFound\u001b[0m: Environment correct-snake-env-name doesn't exist. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "print([env.id for env in gym.envs.registry.all()])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "368ndAx6HmSH",
        "outputId": "57ca9f55-bbc8-4dbf-a094-19fc07da1246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'LunarLander-v2', 'LunarLanderContinuous-v2', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v2', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'Reacher-v2', 'Reacher-v4', 'Pusher-v2', 'Pusher-v4', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'HumanoidStandup-v2', 'HumanoidStandup-v4', 'snake-v0', 'snake-tiled-v0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('snake-v0')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "xUk64Gl-Htn1",
        "outputId": "1ae35c0e-e91f-406a-e3e0-7d88183442b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'snake_gym.envs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cb33767d7680>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'snake-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# Assume it's a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0menv_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"render_mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'snake_gym.envs'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snake-gym\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfT1RhX0H3Zy",
        "outputId": "5f211eb8-3b46-49bb-cac6-28fd5807eafe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: snake-gym in /usr/local/lib/python3.10/dist-packages (1.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('snake-v0')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "Te3MQz-DH3tW",
        "outputId": "911b0fff-03d2-4d64-8043-f3f8db5f7009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'snake_gym.envs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cb33767d7680>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'snake-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# Assume it's a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0menv_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"render_mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'snake_gym.envs'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym-snake\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyXf6oazH4Qq",
        "outputId": "845126b9-128b-4b8c-8b08-bc84d8c867d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym-snake\n",
            "  Downloading gym_snake-0.1.7-py3-none-any.whl.metadata (313 bytes)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from gym-snake) (0.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gym-snake) (1.26.4)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from gym-snake) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->gym-snake) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->gym-snake) (0.0.8)\n",
            "Downloading gym_snake-0.1.7-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: gym-snake\n",
            "Successfully installed gym-snake-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('snake-v0')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "s-3AUU_AH4lW",
        "outputId": "949e34ba-f261-42e8-8d46-c1f00fe9fc1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'snake_gym.envs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cb33767d7680>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'snake-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, new_step_api, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# Assume it's a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0menv_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"render_mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'snake_gym.envs'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "import random\n",
        "import pygame\n",
        "\n",
        "class SnakeEnv(gym.Env):\n",
        "    def __init__(self, grid_size=10):\n",
        "        super(SnakeEnv, self).__init__()\n",
        "\n",
        "        self.grid_size = grid_size\n",
        "        self.action_space = spaces.Discrete(4)  # Up, Down, Left, Right\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.grid_size, self.grid_size), dtype=np.uint8)\n",
        "\n",
        "        self.snake = [(5, 5)]\n",
        "        self.food = None\n",
        "        self.done = False\n",
        "        self.score = 0\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.snake = [(5, 5)]\n",
        "        self.food = self._generate_food()\n",
        "        self.done = False\n",
        "        self.score = 0\n",
        "        return self._get_observation()\n",
        "\n",
        "    def _generate_food(self):\n",
        "        while True:\n",
        "            food = (random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1))\n",
        "            if food not in self.snake:\n",
        "                return food\n",
        "\n",
        "    def _get_observation(self):\n",
        "        obs = np.zeros((self.grid_size, self.grid_size), dtype=np.uint8)\n",
        "        for x, y in self.snake:\n",
        "            obs[x, y] = 1\n",
        "        fx, fy = self.food\n",
        "        obs[fx, fy] = 2\n",
        "        return obs\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.done:\n",
        "            return self._get_observation(), 0, self.done, {}\n",
        "\n",
        "        head_x, head_y = self.snake[0]\n",
        "        if action == 0:  # Up\n",
        "            head_x -= 1\n",
        "        elif action == 1:  # Down\n",
        "            head_x += 1\n",
        "        elif action == 2:  # Left\n",
        "            head_y -= 1\n",
        "        elif action == 3:  # Right\n",
        "            head_y += 1\n",
        "\n",
        "        new_head = (head_x, head_y)\n",
        "\n",
        "        if new_head in self.snake or not (0 <= head_x < self.grid_size and 0 <= head_y < self.grid_size):\n",
        "            self.done = True  # Snake hits the wall or itself\n",
        "            return self._get_observation(), -10, self.done, {}  # Negative reward for dying\n",
        "\n",
        "        self.snake = [new_head] + self.snake[:-1]\n",
        "\n",
        "        if new_head == self.food:\n",
        "            self.snake.append(self.snake[-1])  # Snake grows\n",
        "            self.food = self._generate_food()  # New food\n",
        "            self.score += 1\n",
        "            reward = 10  # Positive reward for eating food\n",
        "        else:\n",
        "            reward = -1  # Small negative reward for each step\n",
        "\n",
        "        return self._get_observation(), reward, self.done, {}\n",
        "\n",
        "    def render(self):\n",
        "        screen = np.zeros((self.grid_size, self.grid_size), dtype=np.uint8)\n",
        "        for x, y in self.snake:\n",
        "            screen[x, y] = 1\n",
        "        fx, fy = self.food\n",
        "        screen[fx, fy] = 2\n",
        "\n",
        "        for row in screen:\n",
        "            print(\" \".join(str(cell) for cell in row))\n",
        "        print()\n",
        "\n",
        "    def close(self):\n",
        "        pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YteyG54IWr5",
        "outputId": "679c9489-50f4-40c2-b0d7-e828755ced1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gym.envs.registration import register\n",
        "\n",
        "register(\n",
        "    id='Snake-v0',\n",
        "    entry_point='__main__:SnakeEnv',\n",
        "    max_episode_steps=100,\n",
        ")\n"
      ],
      "metadata": {
        "id": "y4fTWcTCIbI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('Snake-v0')\n",
        "\n",
        "# Train the model using stable-baselines3 or any RL algorithm\n",
        "env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    action = env.action_space.sample()  # Random action for now\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ww8qs-MrIccZ",
        "outputId": "802a2275-ab37-4004-afa9-d0ad05a1d54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 1 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 1 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 1 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 1 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 1 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 1 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 1 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 1 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 1 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 1 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 1 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 1 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 1 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 1 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 1 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 1 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 1 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 1 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (10, 10)\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:190: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `return_info` to return information from the environment resetting.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:195: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
            "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DQN\n",
        "\n",
        "# Initialize the DQN model\n",
        "model = DQN('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"dqn_snake\")\n",
        "\n",
        "# Evaluate the trained model\n",
        "obs = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "PTs2JfFfIfjY",
        "outputId": "a79dd969-2d6f-444d-b192-fd8f7f6c97ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Missing shimmy installation. You provided an OpenAI Gym environment. Stable-Baselines3 (SB3) has transitioned to using Gymnasium internally. In order to use OpenAI Gym environments with SB3, you need to install shimmy (`pip install 'shimmy>=2.0'`).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py\u001b[0m in \u001b[0;36m_patch_env\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mshimmy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shimmy'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ce1d2b81d4fd>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Initialize the DQN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MlpPolicy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     ) -> None:\n\u001b[0;32m--> 104\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, use_sde_at_warmup, sde_support, supported_action_spaces)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0msupported_action_spaces\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     ):\n\u001b[0;32m--> 110\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_make_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m_wrap_env\u001b[0;34m(env, verbose, monitor_wrapper)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVecEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Patch to support gym 0.21/0.26 and gymnasium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_patch_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmonitor_wrapper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py\u001b[0m in \u001b[0;36m_patch_env\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mshimmy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;34m\"Missing shimmy installation. You provided an OpenAI Gym environment. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;34m\"Stable-Baselines3 (SB3) has transitioned to using Gymnasium internally. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Missing shimmy installation. You provided an OpenAI Gym environment. Stable-Baselines3 (SB3) has transitioned to using Gymnasium internally. In order to use OpenAI Gym environments with SB3, you need to install shimmy (`pip install 'shimmy>=2.0'`).",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'shimmy>=2.0'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBBgwarWIqQf",
        "outputId": "cabb46d6-2adb-4003-81e8-73f45e24a640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shimmy>=2.0\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from shimmy>=2.0) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.10/dist-packages (from shimmy>=2.0) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=2.0) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DQN\n",
        "\n",
        "# Initialize the DQN model\n",
        "model = DQN('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"dqn_snake\")\n",
        "\n",
        "# Evaluate the trained model\n",
        "obs = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EiWLqVyHIroM",
        "outputId": "80efefda-5caf-4a2a-b243-9048d09c152d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 26.2     |\n",
            "|    ep_rew_mean      | -32.5    |\n",
            "|    exploration_rate | 0.9      |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 618      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 105      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.23     |\n",
            "|    n_updates        | 1        |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 24.6     |\n",
            "|    ep_rew_mean      | -32.2    |\n",
            "|    exploration_rate | 0.813    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 721      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 197      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.53     |\n",
            "|    n_updates        | 24       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.2     |\n",
            "|    ep_rew_mean      | -29.2    |\n",
            "|    exploration_rate | 0.759    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 747      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 254      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.674    |\n",
            "|    n_updates        | 38       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.2     |\n",
            "|    ep_rew_mean      | -26.9    |\n",
            "|    exploration_rate | 0.707    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 735      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 308      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.926    |\n",
            "|    n_updates        | 51       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 18.1     |\n",
            "|    ep_rew_mean      | -25.4    |\n",
            "|    exploration_rate | 0.656    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 711      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 362      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.23     |\n",
            "|    n_updates        | 65       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.9     |\n",
            "|    ep_rew_mean      | -24.1    |\n",
            "|    exploration_rate | 0.614    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 725      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 406      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.23     |\n",
            "|    n_updates        | 76       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.4     |\n",
            "|    ep_rew_mean      | -23.8    |\n",
            "|    exploration_rate | 0.565    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 727      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 458      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.606    |\n",
            "|    n_updates        | 89       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.4     |\n",
            "|    ep_rew_mean      | -23      |\n",
            "|    exploration_rate | 0.533    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 492      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.5      |\n",
            "|    n_updates        | 97       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 14.8     |\n",
            "|    ep_rew_mean      | -22.6    |\n",
            "|    exploration_rate | 0.495    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 731      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 532      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.574    |\n",
            "|    n_updates        | 107      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 14.1     |\n",
            "|    ep_rew_mean      | -21.7    |\n",
            "|    exploration_rate | 0.464    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 731      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 564      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.17     |\n",
            "|    n_updates        | 115      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.8     |\n",
            "|    ep_rew_mean      | -21.5    |\n",
            "|    exploration_rate | 0.424    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 735      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 606      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.43     |\n",
            "|    n_updates        | 126      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.2     |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.397    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 735      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 635      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.868    |\n",
            "|    n_updates        | 133      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.9     |\n",
            "|    ep_rew_mean      | -20.6    |\n",
            "|    exploration_rate | 0.364    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 735      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 670      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.46     |\n",
            "|    n_updates        | 142      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.5     |\n",
            "|    ep_rew_mean      | -20.3    |\n",
            "|    exploration_rate | 0.334    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 733      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 701      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.864    |\n",
            "|    n_updates        | 150      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.3     |\n",
            "|    ep_rew_mean      | -20.1    |\n",
            "|    exploration_rate | 0.297    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 736      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 740      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.548    |\n",
            "|    n_updates        | 159      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12       |\n",
            "|    ep_rew_mean      | -19.8    |\n",
            "|    exploration_rate | 0.268    |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 735      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 771      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.11     |\n",
            "|    n_updates        | 167      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.6     |\n",
            "|    ep_rew_mean      | -19.3    |\n",
            "|    exploration_rate | 0.249    |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 733      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 791      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.825    |\n",
            "|    n_updates        | 172      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.4     |\n",
            "|    ep_rew_mean      | -19.2    |\n",
            "|    exploration_rate | 0.221    |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 729      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 820      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.66     |\n",
            "|    n_updates        | 179      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.1     |\n",
            "|    ep_rew_mean      | -18.8    |\n",
            "|    exploration_rate | 0.199    |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 843      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.537    |\n",
            "|    n_updates        | 185      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 10.9     |\n",
            "|    ep_rew_mean      | -18.6    |\n",
            "|    exploration_rate | 0.174    |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 869      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.81     |\n",
            "|    n_updates        | 192      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 10.6     |\n",
            "|    ep_rew_mean      | -18.5    |\n",
            "|    exploration_rate | 0.151    |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 894      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.37     |\n",
            "|    n_updates        | 198      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 10.4     |\n",
            "|    ep_rew_mean      | -18.3    |\n",
            "|    exploration_rate | 0.13     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 719      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 916      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.1      |\n",
            "|    n_updates        | 203      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 10.2     |\n",
            "|    ep_rew_mean      | -18.1    |\n",
            "|    exploration_rate | 0.11     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 711      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 937      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.07     |\n",
            "|    n_updates        | 209      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.99     |\n",
            "|    ep_rew_mean      | -18      |\n",
            "|    exploration_rate | 0.089    |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 704      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 959      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.93     |\n",
            "|    n_updates        | 214      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.85     |\n",
            "|    ep_rew_mean      | -17.8    |\n",
            "|    exploration_rate | 0.0642   |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 699      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 985      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.773    |\n",
            "|    n_updates        | 221      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.02     |\n",
            "|    ep_rew_mean      | -17      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 698      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1007     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.65     |\n",
            "|    n_updates        | 226      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 8.32     |\n",
            "|    ep_rew_mean      | -16.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 691      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1029     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.07     |\n",
            "|    n_updates        | 232      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 7.98     |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 690      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1052     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.07     |\n",
            "|    n_updates        | 237      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 7.68     |\n",
            "|    ep_rew_mean      | -15.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 688      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1076     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.29     |\n",
            "|    n_updates        | 243      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 7.34     |\n",
            "|    ep_rew_mean      | -15.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 686      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1096     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.29     |\n",
            "|    n_updates        | 248      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 7.1      |\n",
            "|    ep_rew_mean      | -15.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 685      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1116     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.702    |\n",
            "|    n_updates        | 253      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 6.84     |\n",
            "|    ep_rew_mean      | -15.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 686      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1142     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.27     |\n",
            "|    n_updates        | 260      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 6.74     |\n",
            "|    ep_rew_mean      | -14.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 682      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1166     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.85     |\n",
            "|    n_updates        | 266      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 6.55     |\n",
            "|    ep_rew_mean      | -14.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 682      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1187     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.974    |\n",
            "|    n_updates        | 271      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 6.49     |\n",
            "|    ep_rew_mean      | -14.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 679      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1213     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.27     |\n",
            "|    n_updates        | 278      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 6.28     |\n",
            "|    ep_rew_mean      | -14.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 676      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1234     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.69     |\n",
            "|    n_updates        | 283      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 6.23     |\n",
            "|    ep_rew_mean      | -14.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 672      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1258     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.24     |\n",
            "|    n_updates        | 289      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 7.15     |\n",
            "|    ep_rew_mean      | -15.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 668      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1385     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.624    |\n",
            "|    n_updates        | 321      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 7.22     |\n",
            "|    ep_rew_mean      | -15.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 667      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1423     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.881    |\n",
            "|    n_updates        | 330      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 7.21     |\n",
            "|    ep_rew_mean      | -15.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 665      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1461     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.861    |\n",
            "|    n_updates        | 340      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 7.18     |\n",
            "|    ep_rew_mean      | -15.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 665      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1489     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.855    |\n",
            "|    n_updates        | 347      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 7.87     |\n",
            "|    ep_rew_mean      | -16      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 664      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1578     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.66     |\n",
            "|    n_updates        | 369      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 8.43     |\n",
            "|    ep_rew_mean      | -16.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 665      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1663     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.37     |\n",
            "|    n_updates        | 390      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 8.44     |\n",
            "|    ep_rew_mean      | -16.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 662      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1687     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.71     |\n",
            "|    n_updates        | 396      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.38     |\n",
            "|    ep_rew_mean      | -17.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 660      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1807     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.541    |\n",
            "|    n_updates        | 426      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.62     |\n",
            "|    ep_rew_mean      | -17.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 658      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1856     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.805    |\n",
            "|    n_updates        | 438      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.99     |\n",
            "|    ep_rew_mean      | -18      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 654      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1915     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.808    |\n",
            "|    n_updates        | 453      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 10.3     |\n",
            "|    ep_rew_mean      | -18.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 658      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1971     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.09     |\n",
            "|    n_updates        | 467      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.8     |\n",
            "|    ep_rew_mean      | -19.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 674      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2134     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.6      |\n",
            "|    n_updates        | 508      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.8     |\n",
            "|    ep_rew_mean      | -19.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 676      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2164     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.13     |\n",
            "|    n_updates        | 515      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.9     |\n",
            "|    ep_rew_mean      | -19.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 679      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2195     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.53     |\n",
            "|    n_updates        | 523      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.9     |\n",
            "|    ep_rew_mean      | -19.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 681      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2220     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.13     |\n",
            "|    n_updates        | 529      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.3     |\n",
            "|    ep_rew_mean      | -20.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 683      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2287     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.531    |\n",
            "|    n_updates        | 546      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.4     |\n",
            "|    ep_rew_mean      | -20.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 685      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2314     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00724  |\n",
            "|    n_updates        | 553      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.4     |\n",
            "|    ep_rew_mean      | -20.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 686      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2339     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.276    |\n",
            "|    n_updates        | 559      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.5     |\n",
            "|    ep_rew_mean      | -20.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 688      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2364     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.14     |\n",
            "|    n_updates        | 565      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.6     |\n",
            "|    ep_rew_mean      | -20.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 690      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2400     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.272    |\n",
            "|    n_updates        | 574      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.7     |\n",
            "|    ep_rew_mean      | -20.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 691      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2431     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.07     |\n",
            "|    n_updates        | 582      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.7     |\n",
            "|    ep_rew_mean      | -20.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 693      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2457     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.27     |\n",
            "|    n_updates        | 589      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.8     |\n",
            "|    ep_rew_mean      | -20.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 694      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2488     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.38     |\n",
            "|    n_updates        | 596      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.9     |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 695      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2529     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.33     |\n",
            "|    n_updates        | 607      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13       |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 697      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2559     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.07     |\n",
            "|    n_updates        | 614      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.1     |\n",
            "|    ep_rew_mean      | -20      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 699      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2591     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.92     |\n",
            "|    n_updates        | 622      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.9     |\n",
            "|    ep_rew_mean      | -20      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 700      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2615     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.272    |\n",
            "|    n_updates        | 628      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.8     |\n",
            "|    ep_rew_mean      | -19.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 701      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2643     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.803    |\n",
            "|    n_updates        | 635      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.8     |\n",
            "|    ep_rew_mean      | -20      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 702      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2673     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.805    |\n",
            "|    n_updates        | 643      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.9     |\n",
            "|    ep_rew_mean      | -20      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 704      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2766     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.39     |\n",
            "|    n_updates        | 666      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.6     |\n",
            "|    ep_rew_mean      | -19.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 707      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2827     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.273    |\n",
            "|    n_updates        | 681      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.8     |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 714      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 2965     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.795    |\n",
            "|    n_updates        | 716      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.8     |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 723      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3084     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.542    |\n",
            "|    n_updates        | 745      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.7     |\n",
            "|    ep_rew_mean      | -20.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 724      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3126     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 756      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.4     |\n",
            "|    ep_rew_mean      | -21.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 732      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3253     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.53     |\n",
            "|    n_updates        | 788      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 14.1     |\n",
            "|    ep_rew_mean      | -22.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 740      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3385     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.539    |\n",
            "|    n_updates        | 821      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.4     |\n",
            "|    ep_rew_mean      | -21.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 743      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3472     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.535    |\n",
            "|    n_updates        | 842      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.4     |\n",
            "|    ep_rew_mean      | -21.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 744      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3505     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.06     |\n",
            "|    n_updates        | 851      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.8     |\n",
            "|    ep_rew_mean      | -21.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 748      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3575     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.528    |\n",
            "|    n_updates        | 868      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 14       |\n",
            "|    ep_rew_mean      | -21.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 750      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3622     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.9      |\n",
            "|    n_updates        | 880      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 14.1     |\n",
            "|    ep_rew_mean      | -21.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 752      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3692     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.808    |\n",
            "|    n_updates        | 897      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.1     |\n",
            "|    ep_rew_mean      | -22.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 758      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 3821     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 930      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.5     |\n",
            "|    ep_rew_mean      | -23.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 761      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 3886     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.794    |\n",
            "|    n_updates        | 946      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.5     |\n",
            "|    ep_rew_mean      | -23.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 762      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 3916     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.32     |\n",
            "|    n_updates        | 953      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.2     |\n",
            "|    ep_rew_mean      | -24.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 766      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4025     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.532    |\n",
            "|    n_updates        | 981      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.2     |\n",
            "|    ep_rew_mean      | -24      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 767      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4053     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.06     |\n",
            "|    n_updates        | 988      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.4     |\n",
            "|    ep_rew_mean      | -24.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 768      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4097     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.05     |\n",
            "|    n_updates        | 999      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.8     |\n",
            "|    ep_rew_mean      | -24.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 770      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4165     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.795    |\n",
            "|    n_updates        | 1016     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.7     |\n",
            "|    ep_rew_mean      | -24.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 771      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4200     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.529    |\n",
            "|    n_updates        | 1024     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.8     |\n",
            "|    ep_rew_mean      | -24.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 772      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4240     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 1034     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.8     |\n",
            "|    ep_rew_mean      | -24.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 773      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4267     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.794    |\n",
            "|    n_updates        | 1041     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.8     |\n",
            "|    ep_rew_mean      | -24.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 773      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4294     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00518  |\n",
            "|    n_updates        | 1048     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 17.5     |\n",
            "|    ep_rew_mean      | -25.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 777      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4390     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.596    |\n",
            "|    n_updates        | 1072     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 18       |\n",
            "|    ep_rew_mean      | -25.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 778      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4473     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.266    |\n",
            "|    n_updates        | 1093     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 17.4     |\n",
            "|    ep_rew_mean      | -24.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 778      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4505     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.08     |\n",
            "|    n_updates        | 1101     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 17       |\n",
            "|    ep_rew_mean      | -24.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 778      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4530     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.806    |\n",
            "|    n_updates        | 1107     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16       |\n",
            "|    ep_rew_mean      | -23.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 779      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4562     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.532    |\n",
            "|    n_updates        | 1115     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.8     |\n",
            "|    ep_rew_mean      | -23.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 780      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4666     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.07     |\n",
            "|    n_updates        | 1141     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.9     |\n",
            "|    ep_rew_mean      | -23.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 779      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 4713     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.536    |\n",
            "|    n_updates        | 1153     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.3     |\n",
            "|    ep_rew_mean      | -24.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 785      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 4885     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.797    |\n",
            "|    n_updates        | 1196     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 17.1     |\n",
            "|    ep_rew_mean      | -24.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 791      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5090     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.11     |\n",
            "|    n_updates        | 1247     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.6     |\n",
            "|    ep_rew_mean      | -24.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 791      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5129     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.06     |\n",
            "|    n_updates        | 1257     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.5     |\n",
            "|    ep_rew_mean      | -24.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 792      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5157     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.786    |\n",
            "|    n_updates        | 1264     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 18       |\n",
            "|    ep_rew_mean      | -26      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 797      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5371     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.532    |\n",
            "|    n_updates        | 1317     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 18       |\n",
            "|    ep_rew_mean      | -25.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 798      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5425     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00716  |\n",
            "|    n_updates        | 1331     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 17.6     |\n",
            "|    ep_rew_mean      | -25.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 799      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5453     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.05     |\n",
            "|    n_updates        | 1338     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 18.6     |\n",
            "|    ep_rew_mean      | -26.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 805      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 5686     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.791    |\n",
            "|    n_updates        | 1396     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 18.4     |\n",
            "|    ep_rew_mean      | -26.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 806      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 5723     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.27     |\n",
            "|    n_updates        | 1405     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.3     |\n",
            "|    ep_rew_mean      | -27      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 808      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 5844     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.29     |\n",
            "|    n_updates        | 1435     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 18.6     |\n",
            "|    ep_rew_mean      | -26.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 809      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 5881     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.84     |\n",
            "|    n_updates        | 1445     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 18.6     |\n",
            "|    ep_rew_mean      | -26.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 809      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 5914     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.54     |\n",
            "|    n_updates        | 1453     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 18.5     |\n",
            "|    ep_rew_mean      | -26.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 808      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 5945     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.263    |\n",
            "|    n_updates        | 1461     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.5     |\n",
            "|    ep_rew_mean      | -27.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 813      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6119     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.258    |\n",
            "|    n_updates        | 1504     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20.1     |\n",
            "|    ep_rew_mean      | -27.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 814      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6205     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.269    |\n",
            "|    n_updates        | 1526     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20.9     |\n",
            "|    ep_rew_mean      | -28.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 816      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6335     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.527    |\n",
            "|    n_updates        | 1558     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.2     |\n",
            "|    ep_rew_mean      | -28.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 817      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6386     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.279    |\n",
            "|    n_updates        | 1571     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.3     |\n",
            "|    ep_rew_mean      | -28.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 817      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6422     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00561  |\n",
            "|    n_updates        | 1580     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21       |\n",
            "|    ep_rew_mean      | -28.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 817      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6486     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.787    |\n",
            "|    n_updates        | 1596     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.5     |\n",
            "|    ep_rew_mean      | -28.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 820      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 6620     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.598    |\n",
            "|    n_updates        | 1629     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.5     |\n",
            "|    ep_rew_mean      | -28.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 819      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 6658     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.528    |\n",
            "|    n_updates        | 1639     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 22.5     |\n",
            "|    ep_rew_mean      | -29.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 821      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 6783     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.525    |\n",
            "|    n_updates        | 1670     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 24.4     |\n",
            "|    ep_rew_mean      | -31.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 824      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7003     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.03     |\n",
            "|    n_updates        | 1725     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.8     |\n",
            "|    ep_rew_mean      | -31      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 825      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7047     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.532    |\n",
            "|    n_updates        | 1736     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.6     |\n",
            "|    ep_rew_mean      | -30.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 825      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7077     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.05     |\n",
            "|    n_updates        | 1744     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.1     |\n",
            "|    ep_rew_mean      | -30.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 828      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7199     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.262    |\n",
            "|    n_updates        | 1774     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 22.2     |\n",
            "|    ep_rew_mean      | -29.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 830      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7312     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00802  |\n",
            "|    n_updates        | 1802     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 22.4     |\n",
            "|    ep_rew_mean      | -29.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 496      |\n",
            "|    fps              | 830      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7372     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.533    |\n",
            "|    n_updates        | 1817     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 22.5     |\n",
            "|    ep_rew_mean      | -29.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 830      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7403     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.854    |\n",
            "|    n_updates        | 1825     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.5     |\n",
            "|    ep_rew_mean      | -28.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 504      |\n",
            "|    fps              | 832      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7524     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.57     |\n",
            "|    n_updates        | 1855     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.3     |\n",
            "|    ep_rew_mean      | -28.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 508      |\n",
            "|    fps              | 832      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7553     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.53     |\n",
            "|    n_updates        | 1863     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.5     |\n",
            "|    ep_rew_mean      | -28.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 512      |\n",
            "|    fps              | 832      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7599     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00465  |\n",
            "|    n_updates        | 1874     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.5     |\n",
            "|    ep_rew_mean      | -26.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 516      |\n",
            "|    fps              | 831      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7634     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 1883     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.4     |\n",
            "|    ep_rew_mean      | -26.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 520      |\n",
            "|    fps              | 831      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7661     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00597  |\n",
            "|    n_updates        | 1890     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.4     |\n",
            "|    ep_rew_mean      | -27      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 524      |\n",
            "|    fps              | 833      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7788     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.537    |\n",
            "|    n_updates        | 1921     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.4     |\n",
            "|    ep_rew_mean      | -27      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 528      |\n",
            "|    fps              | 832      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7825     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.05     |\n",
            "|    n_updates        | 1931     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.5     |\n",
            "|    ep_rew_mean      | -27      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 532      |\n",
            "|    fps              | 832      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7861     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.784    |\n",
            "|    n_updates        | 1940     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.5     |\n",
            "|    ep_rew_mean      | -27      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 536      |\n",
            "|    fps              | 833      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7896     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.36     |\n",
            "|    n_updates        | 1948     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 18.1     |\n",
            "|    ep_rew_mean      | -25.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 540      |\n",
            "|    fps              | 832      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7925     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.519    |\n",
            "|    n_updates        | 1956     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 17.6     |\n",
            "|    ep_rew_mean      | -25.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 544      |\n",
            "|    fps              | 833      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7963     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.575    |\n",
            "|    n_updates        | 1965     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.5     |\n",
            "|    ep_rew_mean      | -24.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 548      |\n",
            "|    fps              | 833      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 7989     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.532    |\n",
            "|    n_updates        | 1972     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.7     |\n",
            "|    ep_rew_mean      | -24.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 552      |\n",
            "|    fps              | 834      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8053     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.515    |\n",
            "|    n_updates        | 1988     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.6     |\n",
            "|    ep_rew_mean      | -24.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 556      |\n",
            "|    fps              | 833      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8077     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.32     |\n",
            "|    n_updates        | 1994     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.2     |\n",
            "|    ep_rew_mean      | -24      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 560      |\n",
            "|    fps              | 833      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8105     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.541    |\n",
            "|    n_updates        | 2001     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 15.1     |\n",
            "|    ep_rew_mean      | -22.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 564      |\n",
            "|    fps              | 833      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8131     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.793    |\n",
            "|    n_updates        | 2007     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.4     |\n",
            "|    ep_rew_mean      | -24.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 568      |\n",
            "|    fps              | 833      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8300     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00654  |\n",
            "|    n_updates        | 2049     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.4     |\n",
            "|    ep_rew_mean      | -24.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 572      |\n",
            "|    fps              | 835      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8423     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.528    |\n",
            "|    n_updates        | 2080     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 14.4     |\n",
            "|    ep_rew_mean      | -22.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 576      |\n",
            "|    fps              | 835      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8447     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.773    |\n",
            "|    n_updates        | 2086     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 14.3     |\n",
            "|    ep_rew_mean      | -22.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 580      |\n",
            "|    fps              | 835      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8478     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.04     |\n",
            "|    n_updates        | 2094     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 14.3     |\n",
            "|    ep_rew_mean      | -22.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 584      |\n",
            "|    fps              | 835      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8510     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.752    |\n",
            "|    n_updates        | 2102     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.4     |\n",
            "|    ep_rew_mean      | -21.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 588      |\n",
            "|    fps              | 835      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8535     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.528    |\n",
            "|    n_updates        | 2108     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.5     |\n",
            "|    ep_rew_mean      | -20.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 592      |\n",
            "|    fps              | 835      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8560     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.522    |\n",
            "|    n_updates        | 2114     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.2     |\n",
            "|    ep_rew_mean      | -20.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 596      |\n",
            "|    fps              | 835      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8588     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.337    |\n",
            "|    n_updates        | 2121     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.2     |\n",
            "|    ep_rew_mean      | -20.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 600      |\n",
            "|    fps              | 835      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8620     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.254    |\n",
            "|    n_updates        | 2129     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.2     |\n",
            "|    ep_rew_mean      | -19.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 604      |\n",
            "|    fps              | 834      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8648     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0121   |\n",
            "|    n_updates        | 2136     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.7     |\n",
            "|    ep_rew_mean      | -20      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 608      |\n",
            "|    fps              | 835      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8724     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.272    |\n",
            "|    n_updates        | 2155     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.6     |\n",
            "|    ep_rew_mean      | -19.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 612      |\n",
            "|    fps              | 835      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8759     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.602    |\n",
            "|    n_updates        | 2164     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.3     |\n",
            "|    ep_rew_mean      | -20.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 616      |\n",
            "|    fps              | 837      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8862     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.252    |\n",
            "|    n_updates        | 2190     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.3     |\n",
            "|    ep_rew_mean      | -20.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 620      |\n",
            "|    fps              | 837      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8888     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.26     |\n",
            "|    n_updates        | 2196     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.3     |\n",
            "|    ep_rew_mean      | -19.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 624      |\n",
            "|    fps              | 837      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8917     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.59     |\n",
            "|    n_updates        | 2204     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.2     |\n",
            "|    ep_rew_mean      | -19.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 628      |\n",
            "|    fps              | 837      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8949     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 2212     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.2     |\n",
            "|    ep_rew_mean      | -19.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 632      |\n",
            "|    fps              | 837      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8982     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0207   |\n",
            "|    n_updates        | 2220     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.1     |\n",
            "|    ep_rew_mean      | -20.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 636      |\n",
            "|    fps              | 838      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9106     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.11     |\n",
            "|    n_updates        | 2251     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.1     |\n",
            "|    ep_rew_mean      | -20.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 640      |\n",
            "|    fps              | 836      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9134     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.25     |\n",
            "|    n_updates        | 2258     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12       |\n",
            "|    ep_rew_mean      | -20.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 644      |\n",
            "|    fps              | 836      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9163     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.586    |\n",
            "|    n_updates        | 2265     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.1     |\n",
            "|    ep_rew_mean      | -20.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 648      |\n",
            "|    fps              | 836      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9195     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.518    |\n",
            "|    n_updates        | 2273     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.4     |\n",
            "|    ep_rew_mean      | -20.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 652      |\n",
            "|    fps              | 838      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9292     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.273    |\n",
            "|    n_updates        | 2297     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.1     |\n",
            "|    ep_rew_mean      | -21.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 656      |\n",
            "|    fps              | 839      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9388     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.261    |\n",
            "|    n_updates        | 2321     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.1     |\n",
            "|    ep_rew_mean      | -21.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 660      |\n",
            "|    fps              | 839      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9412     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.787    |\n",
            "|    n_updates        | 2327     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.8     |\n",
            "|    ep_rew_mean      | -21.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 664      |\n",
            "|    fps              | 840      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9508     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.767    |\n",
            "|    n_updates        | 2351     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.4     |\n",
            "|    ep_rew_mean      | -20.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 668      |\n",
            "|    fps              | 839      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9536     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.861    |\n",
            "|    n_updates        | 2358     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.4     |\n",
            "|    ep_rew_mean      | -19.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 672      |\n",
            "|    fps              | 839      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9568     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.01     |\n",
            "|    n_updates        | 2366     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 11.6     |\n",
            "|    ep_rew_mean      | -19.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 676      |\n",
            "|    fps              | 840      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9605     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0156   |\n",
            "|    n_updates        | 2376     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.3     |\n",
            "|    ep_rew_mean      | -20.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 680      |\n",
            "|    fps              | 841      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9710     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.3      |\n",
            "|    n_updates        | 2402     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.3     |\n",
            "|    ep_rew_mean      | -21.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 684      |\n",
            "|    fps              | 843      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9837     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.519    |\n",
            "|    n_updates        | 2434     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 14.7     |\n",
            "|    ep_rew_mean      | -22.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 688      |\n",
            "|    fps              | 843      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 10000    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.522    |\n",
            "|    n_updates        | 2474     |\n",
            "----------------------------------\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 2 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 2 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 2 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 2 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 1 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 2 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 1 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 2 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 1 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 2 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
            "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import DQN\n",
        "\n",
        "# Initialize the DQN model\n",
        "model = DQN('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"dqn_snake\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4BGCkTxI4iu",
        "outputId": "73926ef5-d06e-42c8-e01f-93d141782428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 39.8     |\n",
            "|    ep_rew_mean      | -48.8    |\n",
            "|    exploration_rate | 0.849    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 2650     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 159      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.412    |\n",
            "|    n_updates        | 14       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 31.6     |\n",
            "|    ep_rew_mean      | -37.9    |\n",
            "|    exploration_rate | 0.76     |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 1957     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 253      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.67     |\n",
            "|    n_updates        | 38       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 27.1     |\n",
            "|    ep_rew_mean      | -33.3    |\n",
            "|    exploration_rate | 0.691    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 1715     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 325      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.665    |\n",
            "|    n_updates        | 56       |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 30.3     |\n",
            "|    ep_rew_mean      | -36      |\n",
            "|    exploration_rate | 0.539    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 1395     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 485      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.355    |\n",
            "|    n_updates        | 96       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 28.9     |\n",
            "|    ep_rew_mean      | -35.2    |\n",
            "|    exploration_rate | 0.452    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 1247     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 577      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.35     |\n",
            "|    n_updates        | 119      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 27.5     |\n",
            "|    ep_rew_mean      | -33.8    |\n",
            "|    exploration_rate | 0.374    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 1167     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 659      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.892    |\n",
            "|    n_updates        | 139      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 24.6     |\n",
            "|    ep_rew_mean      | -30.9    |\n",
            "|    exploration_rate | 0.346    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 1132     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 688      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.296    |\n",
            "|    n_updates        | 146      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.9     |\n",
            "|    ep_rew_mean      | -30.6    |\n",
            "|    exploration_rate | 0.272    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 1043     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 766      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.858    |\n",
            "|    n_updates        | 166      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 22.8     |\n",
            "|    ep_rew_mean      | -29.7    |\n",
            "|    exploration_rate | 0.222    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 1021     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 819      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.13     |\n",
            "|    n_updates        | 179      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.6     |\n",
            "|    ep_rew_mean      | -30.8    |\n",
            "|    exploration_rate | 0.102    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 948      |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 945      |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.07     |\n",
            "|    n_updates        | 211      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 24.2     |\n",
            "|    ep_rew_mean      | -31.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 915      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1065     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.455    |\n",
            "|    n_updates        | 241      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 22.7     |\n",
            "|    ep_rew_mean      | -30      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 907      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1090     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.434    |\n",
            "|    n_updates        | 247      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.4     |\n",
            "|    ep_rew_mean      | -28.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 901      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1115     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.152    |\n",
            "|    n_updates        | 253      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20.8     |\n",
            "|    ep_rew_mean      | -28.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 891      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1162     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.724    |\n",
            "|    n_updates        | 265      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20       |\n",
            "|    ep_rew_mean      | -27.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 874      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1199     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.392    |\n",
            "|    n_updates        | 274      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.1     |\n",
            "|    ep_rew_mean      | -26.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 863      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1225     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.389    |\n",
            "|    n_updates        | 281      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20.6     |\n",
            "|    ep_rew_mean      | -28.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 846      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1403     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.327    |\n",
            "|    n_updates        | 325      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20.1     |\n",
            "|    ep_rew_mean      | -27.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 843      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1450     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.313    |\n",
            "|    n_updates        | 337      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.5     |\n",
            "|    ep_rew_mean      | -26.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 841      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1481     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.299    |\n",
            "|    n_updates        | 345      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.6     |\n",
            "|    ep_rew_mean      | -26.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 829      |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 1572     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0137   |\n",
            "|    n_updates        | 367      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.3     |\n",
            "|    ep_rew_mean      | -28.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 803      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1789     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.284    |\n",
            "|    n_updates        | 422      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20.7     |\n",
            "|    ep_rew_mean      | -27.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 800      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 1824     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.279    |\n",
            "|    n_updates        | 430      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 22       |\n",
            "|    ep_rew_mean      | -29.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 782      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2020     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.269    |\n",
            "|    n_updates        | 479      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.7     |\n",
            "|    ep_rew_mean      | -28.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 776      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2080     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0034   |\n",
            "|    n_updates        | 494      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.2     |\n",
            "|    ep_rew_mean      | -28.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 772      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2117     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 1.19     |\n",
            "|    n_updates        | 504      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.9     |\n",
            "|    ep_rew_mean      | -26.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 770      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2144     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.27     |\n",
            "|    n_updates        | 510      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20.1     |\n",
            "|    ep_rew_mean      | -27.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 764      |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 2266     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.544    |\n",
            "|    n_updates        | 541      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20.4     |\n",
            "|    ep_rew_mean      | -27.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 754      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2361     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00395  |\n",
            "|    n_updates        | 565      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20       |\n",
            "|    ep_rew_mean      | -27.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 744      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2486     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.806    |\n",
            "|    n_updates        | 596      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 19.8     |\n",
            "|    ep_rew_mean      | -26.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 739      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2554     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.807    |\n",
            "|    n_updates        | 613      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20.2     |\n",
            "|    ep_rew_mean      | -27.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 747      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2683     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 645      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 21.3     |\n",
            "|    ep_rew_mean      | -28.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 755      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2814     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 678      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 22.3     |\n",
            "|    ep_rew_mean      | -29.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 766      |\n",
            "|    time_elapsed     | 3        |\n",
            "|    total_timesteps  | 2998     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.272    |\n",
            "|    n_updates        | 724      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23       |\n",
            "|    ep_rew_mean      | -29.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 772      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3116     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.59     |\n",
            "|    n_updates        | 753      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.9     |\n",
            "|    ep_rew_mean      | -30.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 781      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3332     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 807      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23       |\n",
            "|    ep_rew_mean      | -29.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 782      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3366     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.592    |\n",
            "|    n_updates        | 816      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.2     |\n",
            "|    ep_rew_mean      | -30.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 783      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3413     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00275  |\n",
            "|    n_updates        | 828      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.3     |\n",
            "|    ep_rew_mean      | -30.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 785      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3449     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00158  |\n",
            "|    n_updates        | 837      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.5     |\n",
            "|    ep_rew_mean      | -30.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 788      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3511     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.536    |\n",
            "|    n_updates        | 852      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 25.3     |\n",
            "|    ep_rew_mean      | -31.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 798      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3727     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 906      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 25.6     |\n",
            "|    ep_rew_mean      | -32.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 801      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3790     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.271    |\n",
            "|    n_updates        | 922      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 25.5     |\n",
            "|    ep_rew_mean      | -31.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 804      |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 3952     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 962      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 27.1     |\n",
            "|    ep_rew_mean      | -33.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 810      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4164     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.803    |\n",
            "|    n_updates        | 1015     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 28.4     |\n",
            "|    ep_rew_mean      | -34.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 813      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4324     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.531    |\n",
            "|    n_updates        | 1055     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 28.6     |\n",
            "|    ep_rew_mean      | -35.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 816      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4435     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0018   |\n",
            "|    n_updates        | 1083     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 28.3     |\n",
            "|    ep_rew_mean      | -35      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 823      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4618     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.266    |\n",
            "|    n_updates        | 1129     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 29.4     |\n",
            "|    ep_rew_mean      | -36.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 829      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4759     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00111  |\n",
            "|    n_updates        | 1164     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 28.2     |\n",
            "|    ep_rew_mean      | -35.1    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 830      |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 4841     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00147  |\n",
            "|    n_updates        | 1185     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 30.1     |\n",
            "|    ep_rew_mean      | -36.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 836      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5085     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.261    |\n",
            "|    n_updates        | 1246     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 30.9     |\n",
            "|    ep_rew_mean      | -37.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 839      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5205     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00257  |\n",
            "|    n_updates        | 1276     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 32       |\n",
            "|    ep_rew_mean      | -38.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 839      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5343     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.8      |\n",
            "|    n_updates        | 1310     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 32       |\n",
            "|    ep_rew_mean      | -38.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 842      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5464     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.27     |\n",
            "|    n_updates        | 1340     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 32.2     |\n",
            "|    ep_rew_mean      | -38.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 845      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5582     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.799    |\n",
            "|    n_updates        | 1370     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 33.5     |\n",
            "|    ep_rew_mean      | -40.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 852      |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 5839     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00245  |\n",
            "|    n_updates        | 1434     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 34.5     |\n",
            "|    ep_rew_mean      | -41.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 856      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6008     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.861    |\n",
            "|    n_updates        | 1476     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 34.5     |\n",
            "|    ep_rew_mean      | -41.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 858      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6128     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 1506     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 34.3     |\n",
            "|    ep_rew_mean      | -41.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 861      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6248     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.533    |\n",
            "|    n_updates        | 1536     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 34.1     |\n",
            "|    ep_rew_mean      | -41      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 862      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6406     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.329    |\n",
            "|    n_updates        | 1576     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 36       |\n",
            "|    ep_rew_mean      | -42.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 868      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6714     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00106  |\n",
            "|    n_updates        | 1653     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 35       |\n",
            "|    ep_rew_mean      | -41.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 870      |\n",
            "|    time_elapsed     | 7        |\n",
            "|    total_timesteps  | 6832     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.002    |\n",
            "|    n_updates        | 1682     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 36.8     |\n",
            "|    ep_rew_mean      | -43.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 873      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7045     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 1736     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 38.5     |\n",
            "|    ep_rew_mean      | -45      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 876      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7260     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00155  |\n",
            "|    n_updates        | 1789     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 38.7     |\n",
            "|    ep_rew_mean      | -45.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 877      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7316     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 1803     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 38.3     |\n",
            "|    ep_rew_mean      | -44.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 876      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7342     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.799    |\n",
            "|    n_updates        | 1810     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 36.4     |\n",
            "|    ep_rew_mean      | -43      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 876      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7366     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.531    |\n",
            "|    n_updates        | 1816     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 36       |\n",
            "|    ep_rew_mean      | -42.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 876      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7392     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.535    |\n",
            "|    n_updates        | 1822     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 34.9     |\n",
            "|    ep_rew_mean      | -41.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 876      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7444     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 1835     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 34.5     |\n",
            "|    ep_rew_mean      | -41.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 879      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7611     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.265    |\n",
            "|    n_updates        | 1877     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 36.2     |\n",
            "|    ep_rew_mean      | -43      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 885      |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 7943     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00293  |\n",
            "|    n_updates        | 1960     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 37.2     |\n",
            "|    ep_rew_mean      | -43.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 886      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8154     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.526    |\n",
            "|    n_updates        | 2013     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 37.2     |\n",
            "|    ep_rew_mean      | -43.7    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 887      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8338     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00261  |\n",
            "|    n_updates        | 2059     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 37.1     |\n",
            "|    ep_rew_mean      | -43.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 889      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8466     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00501  |\n",
            "|    n_updates        | 2091     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 37.4     |\n",
            "|    ep_rew_mean      | -43.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 890      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8581     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00255  |\n",
            "|    n_updates        | 2120     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 35.3     |\n",
            "|    ep_rew_mean      | -41.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 890      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8615     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 2128     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 35.3     |\n",
            "|    ep_rew_mean      | -41.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 891      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8737     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.531    |\n",
            "|    n_updates        | 2159     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 34.2     |\n",
            "|    ep_rew_mean      | -40.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 891      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8759     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.266    |\n",
            "|    n_updates        | 2164     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 34.1     |\n",
            "|    ep_rew_mean      | -40.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 892      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8874     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.325    |\n",
            "|    n_updates        | 2193     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 33.4     |\n",
            "|    ep_rew_mean      | -39.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 892      |\n",
            "|    time_elapsed     | 9        |\n",
            "|    total_timesteps  | 8922     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.799    |\n",
            "|    n_updates        | 2205     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 31.1     |\n",
            "|    ep_rew_mean      | -37.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 892      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 8949     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.534    |\n",
            "|    n_updates        | 2212     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 31.2     |\n",
            "|    ep_rew_mean      | -37.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 894      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9132     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.798    |\n",
            "|    n_updates        | 2257     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 31.5     |\n",
            "|    ep_rew_mean      | -38      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 895      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9279     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00137  |\n",
            "|    n_updates        | 2294     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 30.6     |\n",
            "|    ep_rew_mean      | -37      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 895      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9306     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00178  |\n",
            "|    n_updates        | 2301     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 29.8     |\n",
            "|    ep_rew_mean      | -36.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 895      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9387     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.802    |\n",
            "|    n_updates        | 2321     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 27.2     |\n",
            "|    ep_rew_mean      | -33.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 895      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9438     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00147  |\n",
            "|    n_updates        | 2334     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 26.3     |\n",
            "|    ep_rew_mean      | -33      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 895      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9464     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00153  |\n",
            "|    n_updates        | 2340     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 24.5     |\n",
            "|    ep_rew_mean      | -31.4    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 895      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9493     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.79     |\n",
            "|    n_updates        | 2348     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 22.6     |\n",
            "|    ep_rew_mean      | -29.6    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 895      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9517     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.531    |\n",
            "|    n_updates        | 2354     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.2     |\n",
            "|    ep_rew_mean      | -30      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 896      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9634     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.269    |\n",
            "|    n_updates        | 2383     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 24.3     |\n",
            "|    ep_rew_mean      | -31.2    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 896      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9773     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00276  |\n",
            "|    n_updates        | 2418     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 24.9     |\n",
            "|    ep_rew_mean      | -31.8    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 897      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9858     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.267    |\n",
            "|    n_updates        | 2439     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 25.2     |\n",
            "|    ep_rew_mean      | -31.9    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 897      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9913     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00273  |\n",
            "|    n_updates        | 2453     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 24.9     |\n",
            "|    ep_rew_mean      | -31.5    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 897      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9933     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.528    |\n",
            "|    n_updates        | 2458     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 23.6     |\n",
            "|    ep_rew_mean      | -30.3    |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 897      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 9967     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.523    |\n",
            "|    n_updates        | 2466     |\n",
            "----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "# Initialize the PPO model\n",
        "model = PPO('MlpPolicy', env, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=10000)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"ppo_snake\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkNdafYBJ4Cm",
        "outputId": "5b07e6dc-165d-440d-dcac-b4e4e77f939a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 29.6     |\n",
            "|    ep_rew_mean     | -36      |\n",
            "| time/              |          |\n",
            "|    fps             | 1233     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 29.2         |\n",
            "|    ep_rew_mean          | -35.4        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 919          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 4            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036127004 |\n",
            "|    clip_fraction        | 0.0041       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.00687      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.76         |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00816     |\n",
            "|    value_loss           | 87.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.2        |\n",
            "|    ep_rew_mean          | -32.4       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 847         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011100222 |\n",
            "|    clip_fraction        | 0.0652      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0.0237      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 16.8        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0189     |\n",
            "|    value_loss           | 41.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 17.4        |\n",
            "|    ep_rew_mean          | -24.4       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 803         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 10          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014148565 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | 0.0156      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.8        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0283     |\n",
            "|    value_loss           | 33.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 15.8        |\n",
            "|    ep_rew_mean          | -21.7       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 745         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014740236 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.31       |\n",
            "|    explained_variance   | -0.0461     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.2        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0303     |\n",
            "|    value_loss           | 30.3        |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained DQN model\n",
        "dqn_model = DQN.load(\"dqn_snake\")\n",
        "\n",
        "# Evaluate the trained DQN model\n",
        "obs = env.reset()\n",
        "done = False\n",
        "total_rewards = 0\n",
        "while not done:\n",
        "    action, _ = dqn_model.predict(obs)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "    total_rewards += reward\n",
        "\n",
        "print(f\"DQN Model Total Rewards: {total_rewards}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG24c5mlJ9Qz",
        "outputId": "660e2ae1-6ff8-4e13-a7f6-b6d102397826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 1 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 1 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 1 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 1 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "1 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 2\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "DQN Model Total Rewards: -86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained PPO model\n",
        "ppo_model = PPO.load(\"ppo_snake\")\n",
        "\n",
        "# Evaluate the trained PPO model\n",
        "obs = env.reset()\n",
        "done = False\n",
        "total_rewards = 0\n",
        "while not done:\n",
        "    action, _ = ppo_model.predict(obs)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "    total_rewards += reward\n",
        "\n",
        "print(f\"PPO Model Total Rewards: {total_rewards}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mBUHLMvJ_14",
        "outputId": "34e9a6bc-5731-4dc8-de9f-b6fe599d7af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 1 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 1 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 1 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 1 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 1 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 1 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 1 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 1 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 1 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 1\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "2 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 1\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "PPO Model Total Rewards: -27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have recorded the rewards for DQN and PPO, plot them\n",
        "dqn_rewards = total_rewards  # From DQN evaluation\n",
        "ppo_rewards = total_rewards  # From PPO evaluation\n",
        "\n",
        "labels = ['DQN', 'PPO']\n",
        "rewards = [dqn_rewards, ppo_rewards]\n",
        "\n",
        "plt.bar(labels, rewards)\n",
        "plt.ylabel('Total Rewards')\n",
        "plt.title('Comparison of DQN and PPO Performance')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "1bSrwt8-KG00",
        "outputId": "a48bc47d-3eba-483e-9dd1-9512d0e5ac32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained DQN model (or PPO)\n",
        "model = DQN.load(\"dqn_snake\")  # Or PPO.load(\"ppo_snake\")\n",
        "\n",
        "# Play a game with the trained model\n",
        "obs = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Rta1IvKKBW",
        "outputId": "2b789bfc-fbbe-43bc-eadc-5f60638a7432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 2 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 1 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 2 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 1 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 2 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 1 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 2 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 1 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 2 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 1\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 2 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 1\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 2 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 1\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 2 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 1\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "0 0 0 0 0 0 0 0 0 0\n",
            "\n"
          ]
        }
      ]
    }
  ]
}